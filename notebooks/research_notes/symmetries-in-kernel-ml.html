<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tristan Bereau">
<meta name="dcterms.date" content="2023-03-23">

<title>Symmetries in kernel-based machine learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="symmetries-in-kernel-ml_files/libs/clipboard/clipboard.min.js"></script>
<script src="symmetries-in-kernel-ml_files/libs/quarto-html/quarto.js"></script>
<script src="symmetries-in-kernel-ml_files/libs/quarto-html/popper.min.js"></script>
<script src="symmetries-in-kernel-ml_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="symmetries-in-kernel-ml_files/libs/quarto-html/anchor.min.js"></script>
<link href="symmetries-in-kernel-ml_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="symmetries-in-kernel-ml_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="symmetries-in-kernel-ml_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="symmetries-in-kernel-ml_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="symmetries-in-kernel-ml_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Symmetries in kernel-based machine learning</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Tristan Bereau </p>
          </div>
  </div>

    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 23, 2023</p>
    </div>
  </div>


  </div>


</header>

<section id="setting" class="level2">
<h2 class="anchored" data-anchor-id="setting">Setting</h2>
<p>We propose to learn a mapping <span class="math inline">\({\bf Q} \rightarrow O\)</span> between the (featurized) representation of sample <span class="math inline">\(i\)</span>, <span class="math inline">\({\bf Q}_i\)</span>, and a target observable, <span class="math inline">\(O_i = O({\bf Q}_i)\)</span>. Examples of <span class="math inline">\(O\)</span> for molecular systems could include a LUMO energy, a binding constant, or a solubility value.</p>
<p>The formalims outlined here follows [Scherer et al.].</p>
</section>
<section id="kernel-machine-learning-101" class="level2">
<h2 class="anchored" data-anchor-id="kernel-machine-learning-101">Kernel machine learning 101</h2>
<p>Training a kernel machine learning (ML) model is equivalent to solving the set of linear equations <span class="math display">\[{\bf O} = \hat{K}{\bf \alpha},\]</span> where the kernel function <span class="math inline">\(K_{ij} = K({\bf Q}_i, {\bf Q}_j) = {\rm Cov}(O_i, O_j)\)</span> measures the similarity between samples <span class="math inline">\({\bf Q}_i\)</span> and <span class="math inline">\({\bf Q}_j\)</span> (via the covariance function), and <span class="math inline">\({\bf \alpha}\)</span> is the (unknown) vector of weight coefficients. Because of the linearity of the equation, we can invert–only if we also <em>regularize</em>–the problem at hand <span class="math display">\[
\alpha = (\hat K + \lambda \mathbb{1})^{-1}{\bf O},
\]</span> where <span class="math inline">\(\lambda\)</span> implements Tikhonov regularization and <span class="math inline">\(\mathbb{1}\)</span> is the identity matrix. Both <span class="math inline">\(\hat K\)</span> and <span class="math inline">\(\mathbb{1}\)</span> are <span class="math inline">\(N \times N\)</span> matrices, while <span class="math inline">\(\alpha\)</span> and <span class="math inline">\({\bf O}\)</span> are both vectors of length <span class="math inline">\(N\)</span>. Here <span class="math inline">\(N\)</span> corresponds to the number of training samples. Determination of the coefficients <span class="math inline">\({\bf \alpha}\)</span> corresponds to <em>training the ML model</em>.</p>
<p>Once trained, we can use it to predict new samples! Given a yet unseen configuration <span class="math inline">\({\bf Q}^*\)</span>, the predicted observable is given by <span class="math display">\[
O({\bf Q}^*) = \sum_{i=1}^N \alpha_i K({\bf Q}_i, {\bf Q}^*).
\tag{1}
\]</span> Eq. (1) takes on a particularly intuitive form: it is a linear expansion of kernel evaluations between each one of the <span class="math inline">\(N\)</span> training points against the new configuration <span class="math inline">\({\bf Q}^*\)</span>. Though it’s linear, this expression is typically far more expressive than a straight-up linear regression because of the so-called kernel trick: the kernel function gathers similarities in a high-dimensional (and implicit!) Hilbert space.</p>
</section>
<section id="noether-theorem" class="level2">
<h2 class="anchored" data-anchor-id="noether-theorem">Noether theorem</h2>
<p>Emmy Noether tells us that to any conservation law, there is an associated symmetry. According to Wikipedia: “To every differentiable symmetry generated by local actions there corresponds a conserved current.”</p>
<p>Important examples:</p>
<ul>
<li>Translational invariance leads to conservation of linear momentum</li>
<li>Rotational invariance leads to conservation of angular momentum</li>
<li>Time invariance leads to convervation of energy</li>
</ul>
</section>
<section id="rotation" class="level2">
<h2 class="anchored" data-anchor-id="rotation">Rotation</h2>
<p>Let’s start with rotations. There are two types of symmetries: invariance and covariance.</p>
<section id="invariance" class="level3">
<h3 class="anchored" data-anchor-id="invariance">Invariance</h3>
<p>Invariance means that the target observable does <em>not</em> depend on the orientation of the sample. Intuitively, the net charge of a molecule (in vacuum) does not depend on its orientation. Making our ML model invariant to rotations simply means ignoring rotational degrees of freedom in the representation. For instance, working with internal coordinates (e.g., pairwise distances) will do just that.</p>
</section>
<section id="covariance" class="level3">
<h3 class="anchored" data-anchor-id="covariance">Covariance</h3>
<p>Covariance is a bit more interesting. Compared to invariance, now the observable will rotate <em>together</em> with the input sample. For instance, the dipole moment of a molecule rotates with the molecule itself.</p>
<p>There are two main routes that lead to covariance ML Models:</p>
<ol type="1">
<li>Preprocess all samples to rotate them in an (arbitrary but consistent) local axis system; train and predict in that local frame; Rotate back in the global frame;</li>
<li>Pick a kernel that correctly orients its prediction based on the input sample</li>
</ol>
<p>Route 1 is relatively easy to implement, and can be a good strategy for small molecules. For larger structures it may turn out challenging to define a local axis system.</p>
<p>Let’s dive into route 2.</p>
<p>First of all, “pick a kernel” means that among the very large number of kernels that one could choose, one / a few / some may have interesting mathematical properties. To be more precise, we’re looking for kernels that know a bit about geometry, and in fact obey the SO(3) rotation group—the group of rotations in 3D space. Because of the 3 dimensions, we will seek a <em>matrix-valued kernel</em>, i.e., one entry in the kernel matrix between any two samples will be of shape <span class="math inline">\(3 \times 3\)</span>.</p>
<p>For simplicity we will focus on two-body interactions. The representation for sample <span class="math inline">\(i\)</span> will be <span class="math inline">\({\bf q}_i = {\bf r}_i\)</span>, where <span class="math inline">\({\bf r}\)</span> is the interparticle vector.</p>
<p>Let’s first define a base (scalar) Gaussian kernel, <span class="math display">\[
k_{\rm b}({\bf q}_m, {\bf q}_l) = \exp\left( - \frac{({\bf r}_m - {\bf r}_l)^2}{2\sigma ^2} \right),
\]</span> which only picks up distance information between the two samples.</p>
<p>Constructing a covariant matrix-valued kernel can be obtained by integrating <span class="math inline">\(k_{\rm b}\)</span> over all rotation matrices, i.e., summing over all actions of the rotation group [Mehta] <span class="math display">\[
\hat \kappa_{\rm c}({\bf q}_m, {\bf q}_l) =
\int {\rm d} \hat{\mathcal{R}} \, \hat{\mathcal{R}} k_{\rm b} ({\bf q}_m, \hat{\mathcal{R}}{\bf q}_l),
\]</span> note how the rotation matrix is applied onto one of the two samples of the kernel function. An insightful paper by [Glielmo et al.] offered an analytical solution for pairs: <span class="math display">\[
\hat \kappa_{\rm c}({\bf q}_m, {\bf q}_l) =
{\rm e}^{-\alpha_{ml}}
\left( \frac{\cosh \gamma_{ml}}{\gamma_{ml}} - \frac{\sinh \gamma_{ml}}{\gamma_{ml}^2} \right)
\hat{{\bf r}}_m \hat{{\bf r}}_l^{\rm T},
\tag{2}
\]</span> where <span class="math inline">\(\alpha_{ml} = r_m^2 + r_l^2 / 4\sigma^2\)</span>, <span class="math inline">\(\gamma_{ml} = r_mr_l/2\sigma^2\)</span>, and <span class="math inline">\(\hat{{\bf r}}_m = {\bf r}_m / r_m\)</span>. What’s important in Eq. (2) is the right-most part of the RHS: the tensor product between the pairwise vectors is <em>solely</em> responsible for the covariance of <span class="math inline">\(\hat \kappa_{\rm c}({\bf q}_m, {\bf q}_l)\)</span>.</p>
</section>
</section>
<section id="energy-conservation" class="level2">
<h2 class="anchored" data-anchor-id="energy-conservation">Energy conservation</h2>
<p>Let’s say we’re learning a force field. Energy conservation can take several forms, including:</p>
<ul>
<li>Curl of the force is zero: <span class="math inline">\(\nabla \times {\bf F} = 0\)</span></li>
<li>Force derives from a potential: <span class="math inline">\({\bf F} = -\nabla E\)</span></li>
</ul>
<p>Let’s select/construct a kernel that implements energy conservation! (See, among others, these important papers: [Macedo &amp; Castro], [Chmiela et al.], [Bartok &amp; Csanyi]). <span class="math display">\[
\begin{align}
\hat\kappa_{\rm h}({\bf q}_m, {\bf q}_l)
&amp;= {\rm Cov}\left( \frac{\partial E({\bf q}_m)}{\partial {\bf r}_m}, \frac{\partial E({\bf q}_l)}{\partial {\bf r}_l} \right) \\
&amp;= \sum_{\alpha, \beta} \frac{\partial^2 k({\bf q}_m, {\bf q}_l)}{\partial q_{m, \alpha}\partial q_{l, \beta}}
\left( \frac{\partial q_{m,\alpha}}{\partial{\bf r}_m} \right)
\left( \frac{\partial q_{l,\beta}}{\partial{\bf r}_l} \right)^{\rm T},
\end{align}
\]</span> which is sometimes called the Hesian kernal, due to the first term of the RHS. While you can try to work out the partial derivatives for a given kernel (e.g., the abovementioned Gaussian kernel), what’s important here again are the <em>other</em> terms: We recognize once again a tensor product! For pairwise interactions, covariance and energy conservation go hand in hand, and lead to matrix-valued kernels with similar characteristics.</p>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<ul>
<li>[Scherer et al.] : <a href="https://dx.doi.org/10.1021/acs.jctc.9b01256" class="uri">https://dx.doi.org/10.1021/acs.jctc.9b01256</a></li>
<li>[Mehta] : Mehta, M. L. Random Matrices; Elsevier: 2004; Vol. 142.</li>
<li>[Glielmo et al.] : <a href="https://link.aps.org/doi/10.1103/PhysRevB.95.214302" class="uri">https://link.aps.org/doi/10.1103/PhysRevB.95.214302</a></li>
<li>[Macedo &amp; Castro] : <a href="https://www.yumpu.com/en/document/view/37810994/learning-divergence-free-and-curl-free-vector-fields-with-matrix-" class="uri">https://www.yumpu.com/en/document/view/37810994/learning-divergence-free-and-curl-free-vector-fields-with-matrix-</a></li>
<li>[Chmiela et al.] : <a href="https://dx.doi.org/10.1126/sciadv.1603015" class="uri">https://dx.doi.org/10.1126/sciadv.1603015</a></li>
<li>[Bartok &amp; Csanyi] : <a href="https://doi.org/10.1002/qua.24927" class="uri">https://doi.org/10.1002/qua.24927</a></li>
</ul>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button,
        { trigger: "manual",
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config);
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>